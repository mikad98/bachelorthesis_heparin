{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMY6N0+NgWvtEz9AFk9IIrC"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Imports\n"
      ],
      "metadata": {
        "id": "LnUdjDwlDYE7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCJ2vq6xDTRC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e58269f-f826-4e77-e202-6747fbe8f2db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import ast\n",
        "from ast import literal_eval\n",
        "from datetime import date\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions"
      ],
      "metadata": {
        "id": "3Es7ZuYKDZgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def subjective_statistics(df: pd.DataFrame):\n",
        "    print(\"========== SUBJECTIVE DATA STATISTICS ==========\")\n",
        "\n",
        "    # Total number of rows\n",
        "    print(f\"\\nTotal datapoints: {len(df)}\")\n",
        "\n",
        "    # Unique user_ids\n",
        "    n_users = df[\"user_id\"].nunique()\n",
        "    print(f\" - Unique users: {n_users}\")\n",
        "\n",
        "    # Gender distribution per user\n",
        "    if \"gender\" in df.columns:\n",
        "        gender_per_user = df.groupby(\"user_id\")[\"gender\"].first().dropna()\n",
        "        gender_counts = gender_per_user.value_counts()\n",
        "        gender_percent = gender_per_user.value_counts(normalize=True) * 100\n",
        "        gender_stats = [f\"{g}: {gender_percent[g]:.2f}% ({gender_counts[g]})\" for g in gender_counts.index]\n",
        "        print(\" - Gender: \" + \", \".join(gender_stats))\n",
        "\n",
        "    # Diagnosis distribution per user\n",
        "    if \"diagnosis\" in df.columns:\n",
        "        diagnosis_per_user = df.groupby(\"user_id\")[\"diagnosis\"].first().dropna()\n",
        "        diag_counts = diagnosis_per_user.value_counts()\n",
        "        diag_percent = diagnosis_per_user.value_counts(normalize=True) * 100\n",
        "        diag_stats = [f\"{d}: {diag_percent[d]:.2f}% ({diag_counts[d]})\" for d in diag_counts.index]\n",
        "        print(\" - Diagnosis: \" + \", \".join(diag_stats))\n",
        "\n",
        "    # Average age per user_id\n",
        "    if \"age\" in df.columns:\n",
        "        age_per_user = df.groupby(\"user_id\")[\"age\"].first().dropna()\n",
        "        mean_age = age_per_user.mean()\n",
        "        std_age = age_per_user.std()\n",
        "        print(f\" - Average age: {mean_age:.2f} ± {std_age:.2f} years\")\n",
        "\n",
        "    # Average, min, max number of entries per user\n",
        "    entries_per_user = df.groupby(\"user_id\").size()\n",
        "    avg_entries = entries_per_user.mean()\n",
        "    med_entries = entries_per_user.median()\n",
        "    min_entries = entries_per_user.min()\n",
        "    max_entries = entries_per_user.max()\n",
        "    print(f\" - Entries per user: avg = {avg_entries:.2f}, med = {med_entries:.2f}, min = {min_entries}, max = {max_entries}\")\n",
        "\n",
        "    # Column completeness\n",
        "    print(\"\\nData completeness:\")\n",
        "    completeness = df.notna().mean() * 100\n",
        "    counts = df.notna().sum()\n",
        "\n",
        "    completeness_summary = {}\n",
        "    for col in df.columns:\n",
        "        comp = round(completeness[col], 2)\n",
        "        valid_count = counts[col]\n",
        "        key = f\"{comp:.2f}% ({valid_count})\"\n",
        "        completeness_summary.setdefault(key, []).append(col)\n",
        "\n",
        "    for key, cols in sorted(completeness_summary.items(),\n",
        "                            key=lambda x: float(x[0].split(\"%\")[0]),\n",
        "                            reverse=True):\n",
        "        print(f\" - {key}: {', '.join(cols)}\")\n",
        "\n",
        "    # Symptom severity distribution\n",
        "    if \"symptom_deg\" in df.columns:\n",
        "        print(\"\\nDistribution of 'symptom_deg':\")\n",
        "        counts = df[\"symptom_deg\"].value_counts().sort_index()\n",
        "        percentages = df[\"symptom_deg\"].value_counts(normalize=True).sort_index() * 100\n",
        "        for val in counts.index:\n",
        "            if percentages[val] > 0:\n",
        "                print(f\" - {val}: {percentages[val]:.2f}% ({counts[val]})\")\n",
        "            else:\n",
        "                print(f\" - {val}: {percentages[val]:.2f}%\")\n",
        "\n",
        "    # Flare perception\n",
        "    if \"rate_as_flare\" in df.columns:\n",
        "        print(\"\\nDistribution of 'rate_as_flare':\")\n",
        "        counts = df[\"rate_as_flare\"].value_counts()\n",
        "        percentages = df[\"rate_as_flare\"].value_counts(normalize=True) * 100\n",
        "        for val in counts.index:\n",
        "            if percentages[val] > 0:\n",
        "                print(f\" - {val}: {percentages[val]:.2f}% ({counts[val]})\")\n",
        "            else:\n",
        "                print(f\" - {val}: {percentages[val]:.2f}%\")\n",
        "\n",
        "def objective_statistics(df: pd.DataFrame):\n",
        "    print(\"========== OBJECTIVE DATA STATISTICS ==========\")\n",
        "\n",
        "    # Total number of rows\n",
        "    print(f\"\\nTotal datapoints: {len(df)}\")\n",
        "\n",
        "    # Unique user_ids\n",
        "    n_users = df[\"user_id\"].nunique()\n",
        "    print(f\" - Unique users: {n_users}\")\n",
        "\n",
        "    # Average, min, max number of entries per user\n",
        "    entries_per_user = df.groupby(\"user_id\").size()\n",
        "    avg_entries = entries_per_user.mean()\n",
        "    med_entries = entries_per_user.median()\n",
        "    min_entries = entries_per_user.min()\n",
        "    max_entries = entries_per_user.max()\n",
        "    print(f\" - Entries per user: avg = {avg_entries:.2f}, med = {med_entries:.2f}, min = {min_entries}, max = {max_entries}\")\n",
        "\n",
        "    # Column completeness\n",
        "    print(\"\\nData completeness:\")\n",
        "    completeness = df.notna().mean() * 100\n",
        "    counts = df.notna().sum()\n",
        "\n",
        "    completeness_summary = {}\n",
        "    for col in df.columns:\n",
        "        comp = round(completeness[col], 2)\n",
        "        valid_count = counts[col]\n",
        "        key = f\"{comp:.2f}% ({valid_count})\"\n",
        "        completeness_summary.setdefault(key, []).append(col)\n",
        "\n",
        "    for key, cols in sorted(completeness_summary.items(),\n",
        "                            key=lambda x: float(x[0].split(\"%\")[0]),\n",
        "                            reverse=True):\n",
        "        print(f\" - {key}: {', '.join(cols)}\")\n",
        "\n",
        "    # Datapoints grouped by provider\n",
        "    if \"provider\" in df.columns:\n",
        "        print(\"\\nWearable Provider:\")\n",
        "        provider_counts = df[\"provider\"].value_counts()\n",
        "        for provider, count in provider_counts.items():\n",
        "            pct = count / len(df) * 100\n",
        "            if pct > 0:\n",
        "                print(f\" - {provider}: {pct:.2f}% ({count})\")\n",
        "            else:\n",
        "                print(f\" - {provider}: {pct:.2f}%\")\n",
        "\n",
        "def merged_statistics(df: pd.DataFrame):\n",
        "    print(\"========== MERGED DATA STATISTICS ==========\")\n",
        "\n",
        "    # Total number of rows\n",
        "    print(f\"\\nTotal datapoints: {len(df)}\")\n",
        "\n",
        "    # Unique user_ids\n",
        "    n_users = df[\"user_id\"].nunique()\n",
        "    print(f\" - Unique users: {n_users}\")\n",
        "\n",
        "    # Gender distribution per user\n",
        "    if \"gender\" in df.columns:\n",
        "        gender_per_user = df.groupby(\"user_id\")[\"gender\"].first().dropna()\n",
        "        gender_counts = gender_per_user.value_counts()\n",
        "        gender_percent = gender_per_user.value_counts(normalize=True) * 100\n",
        "        gender_stats = [f\"{g}: {gender_percent[g]:.2f}% ({gender_counts[g]})\" for g in gender_counts.index]\n",
        "        print(\" - Gender: \" + \", \".join(gender_stats))\n",
        "\n",
        "    # Diagnosis distribution per user\n",
        "    if \"diagnosis\" in df.columns:\n",
        "        diagnosis_per_user = df.groupby(\"user_id\")[\"diagnosis\"].first().dropna()\n",
        "        diag_counts = diagnosis_per_user.value_counts()\n",
        "        diag_percent = diagnosis_per_user.value_counts(normalize=True) * 100\n",
        "        diag_stats = [f\"{d}: {diag_percent[d]:.2f}% ({diag_counts[d]})\" for d in diag_counts.index]\n",
        "        print(\" - Diagnosis: \" + \", \".join(diag_stats))\n",
        "\n",
        "    # Average age per user_id\n",
        "    if \"age\" in df.columns:\n",
        "        age_per_user = df.groupby(\"user_id\")[\"age\"].first().dropna()\n",
        "        mean_age = age_per_user.mean()\n",
        "        std_age = age_per_user.std()\n",
        "        print(f\" - Average age: {mean_age:.2f} ± {std_age:.2f} years\")\n",
        "\n",
        "    # Average, min, max number of entries per user\n",
        "    entries_per_user = df.groupby(\"user_id\").size()\n",
        "    avg_entries = entries_per_user.mean()\n",
        "    med_entries = entries_per_user.median()\n",
        "    min_entries = entries_per_user.min()\n",
        "    max_entries = entries_per_user.max()\n",
        "    print(f\" - Entries per user: avg = {avg_entries:.2f}, med = {med_entries:.2f}, min = {min_entries}, max = {max_entries}\")\n",
        "\n",
        "    # Column completeness\n",
        "    print(\"\\nData completeness:\")\n",
        "    completeness = df.notna().mean() * 100\n",
        "    counts = df.notna().sum()\n",
        "\n",
        "    completeness_summary = {}\n",
        "    for col in df.columns:\n",
        "        comp = round(completeness[col], 2)\n",
        "        valid_count = counts[col]\n",
        "        key = f\"{comp:.2f}% ({valid_count})\"\n",
        "        completeness_summary.setdefault(key, []).append(col)\n",
        "\n",
        "    for key, cols in sorted(completeness_summary.items(),\n",
        "                            key=lambda x: float(x[0].split(\"%\")[0]),\n",
        "                            reverse=True):\n",
        "        print(f\" - {key}: {', '.join(cols)}\")\n",
        "\n",
        "    # Symptom severity distribution\n",
        "    if \"symptom_deg\" in df.columns:\n",
        "        print(\"\\nSymptom severity distribution (symptom_deg):\")\n",
        "        counts = df[\"symptom_deg\"].value_counts().sort_index()\n",
        "        percentages = df[\"symptom_deg\"].value_counts(normalize=True).sort_index() * 100\n",
        "        for val in counts.index:\n",
        "            if percentages[val] > 0:\n",
        "                print(f\" - {val}: {percentages[val]:.2f}% ({counts[val]})\")\n",
        "            else:\n",
        "                print(f\" - {val}: {percentages[val]:.2f}%\")\n",
        "\n",
        "    # Flare perception\n",
        "    if \"rate_as_flare\" in df.columns:\n",
        "        print(\"\\nDistribution of 'rate_as_flare':\")\n",
        "        counts = df[\"rate_as_flare\"].value_counts()\n",
        "        percentages = df[\"rate_as_flare\"].value_counts(normalize=True) * 100\n",
        "        for val in counts.index:\n",
        "            if percentages[val] > 0:\n",
        "                print(f\" - {val}: {percentages[val]:.2f}% ({counts[val]})\")\n",
        "            else:\n",
        "                print(f\" - {val}: {percentages[val]:.2f}%\")"
      ],
      "metadata": {
        "id": "wwnMmS0jDbQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Data"
      ],
      "metadata": {
        "id": "UA0S15adDces"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subjective = pd.read_csv('/content/drive/My Drive/coreway_ml/Thesis - Mika/subjective.csv')\n",
        "objective = pd.read_csv('/content/drive/My Drive/coreway_ml/Thesis - Mika/objective.csv')\n",
        "merged = pd.read_csv('/content/drive/My Drive/coreway_ml/Thesis - Mika/merged.csv')"
      ],
      "metadata": {
        "id": "Lah0XQm2Dbhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Subjective Statistics"
      ],
      "metadata": {
        "id": "EhqoKnwLPF-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subjective_statistics(subjective)"
      ],
      "metadata": {
        "id": "xrAK6AooHPjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Objective Statistics"
      ],
      "metadata": {
        "id": "TIuklnMSPLS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "objective_statistics(objective)"
      ],
      "metadata": {
        "id": "DOKxUdARPLcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Merged Statistics"
      ],
      "metadata": {
        "id": "P6ZdHNUtRYZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_statistics(merged)"
      ],
      "metadata": {
        "id": "6Ax61Y2WRWLk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}